{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "b'APcACAAAAAAAAAAACAD3AEIAAAAAAAAAAAAAAAAAAEIkAAAAAAAAAAAAAAAAAAAkgQAAAAAAAAAAAAAAAAAAgRAAAAAAAAAAAAAAAAAAABAIAAAAAAAAAAAAAAAAAAAI+AAAAFM='\n"
     ]
    }
   ],
   "source": [
    "from peewee import *\n",
    "import base64\n",
    "\n",
    "db = SqliteDatabase('koth_training.db')\n",
    "\n",
    "class Training_data(Model):\n",
    "  id = IntegerField()\n",
    "  binary = BlobField()\n",
    "  evals = FloatField()\n",
    "\n",
    "  class Meta:\n",
    "    database = db\n",
    "\n",
    "  def binary_base64(self):\n",
    "    return base64.b64encode(self.binary)\n",
    "db.connect()\n",
    "LABEL_COUNT = 1000000\n",
    "print(LABEL_COUNT)\n",
    "eval = Training_data.get(Training_data.id == 1)\n",
    "print(eval.binary_base64())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset, random_split\n",
    "import pytorch_lightning as pl\n",
    "from random import randrange\n",
    "\n",
    "class EvaluationDataset(IterableDataset):\n",
    "  def __init__(self, count):\n",
    "    self.count = count\n",
    "  def __iter__(self):\n",
    "    return self\n",
    "  def __next__(self):\n",
    "    idx = randrange(self.count)\n",
    "    return self[idx]\n",
    "  def __len__(self):\n",
    "    return self.count\n",
    "  def __getitem__(self, idx):\n",
    "    eval = Training_data.get(Training_data.id == idx+1)\n",
    "    bin = np.frombuffer(eval.binary, dtype=np.uint8)\n",
    "    bin = np.unpackbits(bin, axis=0).astype(np.single) \n",
    "    eval.evals = max(eval.evals, -15)\n",
    "    eval.evals = min(eval.evals, 15)\n",
    "    ev = np.array([eval.evals]).astype(np.single) \n",
    "    return {'binary':bin, 'eval':ev}    \n",
    "\n",
    "dataset = EvaluationDataset(count=LABEL_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | seq  | Sequential | 3.3 M \n",
      "------------------------------------\n",
      "3.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.3 M     Total params\n",
      "6.538     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3%|▎         | 63/1954 [05:38<2:49:24,  5.38s/it, loss=nan, v_num=nt-4]\n",
      "Epoch 0:   6%|▌         | 118/1954 [04:46<1:14:17,  2.43s/it, loss=inf, v_num=nt-4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best initial lr: 100%|██████████| 25/25 [04:05<00:00,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:   4%|▍         | 78/1954 [04:00<1:36:21,  3.08s/it, loss=inf, v_num=nt-4]\n",
      "Epoch 0:  53%|█████▎    | 513/977 [03:28<03:08,  2.46it/s, loss=2.54, v_num=nt-6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 977/977 [06:37<00:00,  2.46it/s, loss=2.22, v_num=nt-6]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "class EvaluationModel(pl.LightningModule):\n",
    "  def __init__(self,learning_rate=1e-3,batch_size=1024,layer_count=10):\n",
    "    super().__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.learning_rate = learning_rate\n",
    "    layers = []\n",
    "    for i in range(layer_count-1):\n",
    "      layers.append((f\"linear-{i}\", nn.Linear(808, 808)))\n",
    "      layers.append((f\"relu-{i}\", nn.ReLU()))\n",
    "    layers.append((f\"linear-{layer_count-1}\", nn.Linear(808, 1)))\n",
    "    self.seq = nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.seq(x)\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    x, y = batch['binary'], batch['eval']\n",
    "    y_hat = self(x)\n",
    "    loss = F.l1_loss(y_hat, y)\n",
    "    self.log(\"train_loss\", loss)\n",
    "    return loss\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    dataset = EvaluationDataset(count=LABEL_COUNT)\n",
    "    return DataLoader(dataset, batch_size=self.batch_size, num_workers=0)\n",
    "\n",
    "configs = [\n",
    "           #{\"layer_count\": 4, \"batch_size\": 512},\n",
    "           {\"layer_count\": 6, \"batch_size\": 1024},\n",
    "           ]\n",
    "for config in configs:\n",
    "  version_name = f'{int(time.time())}-batch_size-{config[\"batch_size\"]}-layer_count-{config[\"layer_count\"]}'\n",
    "  logger = pl.loggers.TensorBoardLogger(\"lightning_logs\", name=\"chessml\", version=version_name)\n",
    "  trainer = pl.Trainer(gpus=1,precision=16,max_epochs=1,auto_lr_find=True,logger=logger)\n",
    "  model = EvaluationModel(layer_count=config[\"layer_count\"],batch_size=config[\"batch_size\"],learning_rate=1e-3)\n",
    "  #trainer.tune(model)\n",
    "  #lr_finder = trainer.tuner.lr_find(model, min_lr=1e-6, max_lr=1e-3, num_training=25)\n",
    "  #fig = lr_finder.plot(suggest=True)\n",
    "  #fig.show()\n",
    "  trainer.fit(model)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_2-22.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7787], grad_fn=<AddBackward0>) 0\n"
     ]
    }
   ],
   "source": [
    "model = EvaluationModel(layer_count=4,batch_size=1024,learning_rate=1e-3)\n",
    "model.load_state_dict(torch.load('model_2-3.pt'))\n",
    "model.eval()\n",
    "start = time.time_ns()\n",
    "bin = np.frombuffer(eval.binary, dtype=np.uint8)\n",
    "bin = np.unpackbits(bin, axis=0).astype(np.single) \n",
    "bin = torch.from_numpy(bin)\n",
    "x = model(bin)\n",
    "end = time.time_ns()\n",
    "print(x, end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "277d713a2869ad522e0f58de96fa3cb2620734b34dd3b3afd7f1966d69d2580f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
